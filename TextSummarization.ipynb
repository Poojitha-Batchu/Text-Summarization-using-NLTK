{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import heapq"
      ],
      "metadata": {
        "id": "0VT_QwXXOG8i"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "rGKCdC3fOHT6",
        "outputId": "f6fd9fa0-6039-4fd6-dc5f-1dea789915ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "vjLjr5M9OHf7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "words = []"
      ],
      "metadata": {
        "id": "2S9mM33jOHlL",
        "outputId": "ef1f5f75-920d-44fb-ce39-8c235aa73517",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def summarize_fun(paragraph, num_sentences = 2):\n",
        "  words = []\n",
        "\n",
        "  paragraph = re.sub(r'\\s+', ' ', paragraph)  # Remove extra spaces\n",
        "  #tokenizing paragraph into sentences\n",
        "  sentences = sent_tokenize(paragraph)\n",
        "  sentences = [sentence.strip() for sentence in sentences]\n",
        "\n",
        "  #tokenizing sentences into words and converting them into lowercase\n",
        "  for sentence in sentences:\n",
        "    words.extend(word.lower() for word in word_tokenize(sentence))\n",
        "\n",
        "  # removing punctuations\n",
        "  words = [word for word in words if word.isalnum()]\n",
        "  # print(sentences)\n",
        "  # print(words)\n",
        "\n",
        "  #removing stopwords from words list\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  words = [word for word in words if word not in stop_words]\n",
        "  # print(words)\n",
        "\n",
        "\n",
        "  #computing word frequencies\n",
        "  word_frequencies = {}\n",
        "  for word in words:\n",
        "    word_frequencies[word] = word_frequencies.get(word, 0) + 1\n",
        "\n",
        "  # print(word_frequencies)\n",
        "\n",
        " # Normalize frequencies (avoid division by zero)\n",
        "    if word_frequencies:\n",
        "        max_frequency = max(word_frequencies.values())\n",
        "        for word in word_frequencies:\n",
        "            word_frequencies[word] = round(word_frequencies[word] / max_frequency, 2)\n",
        "\n",
        "  # print(word_frequencies)\n",
        "\n",
        "#   Higher values (close to 1.0) indicate important words in the text.\n",
        "#   Lower values mean the word appears less frequently and is likely less significant\n",
        "\n",
        "\n",
        "  sentence_scores = {}\n",
        "  for sentence in sentences:\n",
        "    sentence_words = word_tokenize(sentence.lower())\n",
        "    sentence_scores[sentence] = round(sum(word_frequencies.get(word, 0) for word in sentence_words if word.isalnum()), 2)\n",
        "  # print(sentence_scores)\n",
        "\n",
        "\n",
        "# Select top sentences\n",
        "  summarized_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
        "  summary = ' '.join(summarized_sentences)\n",
        "\n",
        "  return summary\n",
        "\n",
        "# paragraph = \"\"\"\n",
        "#     Natural language processing (NLP) is a sub-field of artificial intelligence (AI) that focuses on the interaction between\n",
        "#     computers and humans through natural language. The ultimate goal of NLP is to enable computers to understand, interpret,\n",
        "#     and generate human languages in a way that is both meaningful and useful. NLP techniques are used in various applications\n",
        "#     such as chatbots, machine translation, sentiment analysis, and text summarization.\n",
        "#     \"\"\"\n",
        "# summarize_fun(paragraph)"
      ],
      "metadata": {
        "id": "Sh7nOLwZOqc1"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = input('Enter a paragraph: ')\n",
        "print('\\n \\n summarized paragraph:' , summarize_fun(paragraph))"
      ],
      "metadata": {
        "id": "iRyg3sICPRZP",
        "outputId": "50090244-864a-4916-8f83-038a19fc783c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a paragraph: The answer was within her reach. It was hidden in a box and now that box sat directly in front of her. She'd spent years searching for it and could hardly believe she'd finally managed to find it. She turned the key to unlock the box and then gently lifted the top. She held her breath in anticipation of finally knowing the answer she had spent so much of her time in search of. As the lid came off she could see that the box was empty.\n",
            "\n",
            " \n",
            " summarized paragraph: As the lid came off she could see that the box was empty. She held her breath in anticipation of finally knowing the answer she had spent so much of her time in search of.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OeHbl2xjzY4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}